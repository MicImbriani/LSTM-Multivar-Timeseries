{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Deep Learning2",
      "language": "python",
      "name": "deep_learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSTM_TEST3 Adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V80ejwHT5_vv"
      },
      "source": [
        "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TJDq3Tv5_v7"
      },
      "source": [
        "# prepare data for lstm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJ8N4xB5_v9"
      },
      "source": [
        "# https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df =  DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(-i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLHE-1Ts5_v-"
      },
      "source": [
        "# load dataset\n",
        "dataset = read_csv('SeoulBikeData_168.csv', encoding= 'unicode_escape', header=0, index_col=0)\n",
        "\n",
        "values = dataset.values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xztLdIb5_v-"
      },
      "source": [
        "# encode the categorical variables into integers\n",
        "label_encoder = LabelEncoder()\n",
        "values[:,12] = label_encoder.fit_transform(values[:,12])\n",
        "values[:,10] = label_encoder.fit_transform(values[:,10])\n",
        "values[:,11] = label_encoder.fit_transform(values[:,11])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnaVTr5S5_v_"
      },
      "source": [
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#scaled = scaler.fit_transform(values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM32xHas5_wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d16274-4506-43b9-d161-a31169493d69"
      },
      "source": [
        "# frame as supervised learning\n",
        "hours_to_consider = 168\n",
        "reframed = series_to_supervised(values, hours_to_consider, 1)\n",
        "\n",
        "# drop columns we don't want to predict\n",
        "columns_to_keep = list()\n",
        "for i in range(337,reframed.shape[1]+1,14):\n",
        "  columns_to_keep.append(i)\n",
        "\n",
        "n_cols = [i for i in range (337,reframed.shape[1]+1)]\n",
        "for i in columns_to_keep:\n",
        "    n_cols.remove(i)\n",
        "n_cols2 = [x - 1 for x in n_cols]\n",
        "print(reframed)\n",
        "reframed = reframed.drop(reframed.columns[[n_cols2]], axis=1, inplace=False)\n",
        "print(reframed)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      var1(t-168)  var2(t-168)  var3(t-168)  ...  var12(t)  var13(t)  var14(t)\n",
            "0           254.0          0.0         -5.2  ...       1.0       1.0      12.0\n",
            "1           204.0          1.0         -5.5  ...       1.0       1.0      12.0\n",
            "2           173.0          2.0         -6.0  ...       1.0       1.0      12.0\n",
            "3           107.0          3.0         -6.2  ...       1.0       1.0      12.0\n",
            "4            78.0          4.0         -6.0  ...       1.0       1.0      12.0\n",
            "...           ...          ...          ...  ...       ...       ...       ...\n",
            "8755       1003.0         19.0          4.2  ...       1.0       1.0      11.0\n",
            "8756        764.0         20.0          3.4  ...       1.0       1.0      11.0\n",
            "8757        694.0         21.0          2.6  ...       1.0       1.0      11.0\n",
            "8758        712.0         22.0          2.1  ...       1.0       1.0      11.0\n",
            "8759        584.0         23.0          1.9  ...       1.0       1.0      11.0\n",
            "\n",
            "[8760 rows x 2366 columns]\n",
            "      var1(t-168)  var2(t-168)  var3(t-168)  ...  var1(t-2)  var1(t-1)  var1(t)\n",
            "0           254.0          0.0         -5.2  ...      167.0      253.0    249.0\n",
            "1           204.0          1.0         -5.5  ...      136.0      167.0    253.0\n",
            "2           173.0          2.0         -6.0  ...       75.0      136.0    167.0\n",
            "3           107.0          3.0         -6.2  ...       47.0       75.0    136.0\n",
            "4            78.0          4.0         -6.0  ...       39.0       47.0     75.0\n",
            "...           ...          ...          ...  ...        ...        ...      ...\n",
            "8755       1003.0         19.0          4.2  ...      679.0      767.0   1007.0\n",
            "8756        764.0         20.0          3.4  ...      729.0      679.0    767.0\n",
            "8757        694.0         21.0          2.6  ...      548.0      729.0    679.0\n",
            "8758        712.0         22.0          2.1  ...      499.0      548.0    729.0\n",
            "8759        584.0         23.0          1.9  ...      507.0      499.0    548.0\n",
            "\n",
            "[8760 rows x 481 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URZ1t7D7K9h7"
      },
      "source": [
        "import pandas as pd\n",
        "my_list = pd.DataFrame(reframed)\n",
        "my_list = my_list.columns.values.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUQgR2Ue5_wB"
      },
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "train_ratio = 0.85\n",
        "n_train_hours = int(365 * hours_to_consider * train_ratio)\n",
        "\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, 1:], train[:, 0]\n",
        "test_X, test_y = test[:, 1:], test[:, 0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r82ZRX7w_vzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7eb412-8751-4e3f-ca17-abae7392f9e0"
      },
      "source": [
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8760, 1, 480) (8760,) (0, 1, 480) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcWBXXCA5_wC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da33f9c-e031-4143-9a26-ca80da838ee4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "from keras.metrics import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.metrics import MeanAbsoluteError\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "!pip install keras-tuner\n",
        "from kerastuner.tuners import RandomSearch, Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers import Reshape\n",
        "\n",
        "def adj_r2(r2):\n",
        "  n = train_X.shape[0]\n",
        "  p = train_X.shape[2]\n",
        "  return (1-(1-r2)*(n-1)/(n-p-1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 10.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=39af293c754ebecd83fcf9ca9fd35c8ee1025a1f109abe52b406def600676305\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=c560a255346c426102e1b6a38bd6b4cb9458ee436c1941a581f0249085f0b77c\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JHbtIkP3jQa",
        "outputId": "0e7455b3-fe5a-4916-9976-5d385707ae98"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "  model.add(LSTM(hp_units,\n",
        "                 input_shape=(train_X.shape[1], train_X.shape[2]),\n",
        "                 return_sequences=True\n",
        "                 ))\n",
        "  model.add(BatchNormalization(axis=-1, \n",
        "                            momentum=0.99,\n",
        "                            epsilon=0.001,\n",
        "                            center=True,\n",
        "                            scale=True,\n",
        "                            beta_initializer='zeros',\n",
        "                            gamma_initializer='ones',\n",
        "                            moving_mean_initializer='zeros',\n",
        "                            moving_variance_initializer='ones',\n",
        "                            beta_regularizer=None,\n",
        "                            gamma_regularizer=None,\n",
        "                            beta_constraint=None,\n",
        "                            gamma_constraint=None\n",
        "                            ))\n",
        "\n",
        "  # model.add(Reshape((train_X.shape[1], train_X.shape[2]), input_shape=(3,)))\n",
        "\n",
        "  # hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "  # model.add(LSTM(hp_units2, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  # model.add(BatchNormalization(axis=-1, \n",
        "  #                           momentum=0.99,\n",
        "  #                           epsilon=0.001,\n",
        "  #                           center=True,\n",
        "  #                           scale=True,\n",
        "  #                           beta_initializer='zeros',\n",
        "  #                           gamma_initializer='ones',\n",
        "  #                           moving_mean_initializer='zeros',\n",
        "  #                           moving_variance_initializer='ones',\n",
        "  #                           beta_regularizer=None,\n",
        "  #                           gamma_regularizer=None,\n",
        "  #                           beta_constraint=None,\n",
        "  #                           gamma_constraint=None))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('lr', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6])\n",
        "  \n",
        "  model.compile(optimizer=Adam(hp_learning_rate),\n",
        "                loss=\"mse\",\n",
        "                metrics=['accuracy', MeanSquaredError(), RootMeanSquaredError(),MeanAbsoluteError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "tuner = Hyperband(model_builder,\n",
        "                  objective='mean_squared_error',\n",
        "                  max_epochs=100,\n",
        "                  factor=10,\n",
        "                  directory='my_dir',\n",
        "                  hyperband_iterations=5,\n",
        "                  project_name='logss')\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "tuner.search(train_X, train_y, epochs=1000, validation_split=0.15, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Number of units in the first densely-connected layer: {best_hps.get('units1')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('lr')}.\"\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 95 Complete [00h 00m 05s]\n",
            "mean_squared_error: 906895.375\n",
            "\n",
            "Best mean_squared_error So Far: 419036.625\n",
            "Total elapsed time: 00h 09m 32s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "Number of units in the first densely-connected layer: 512 and the optimal learning rate for the optimizer\n",
            "is 0.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOTX2CXz-d6i",
        "outputId": "f9342533-eeb9-45b5-febf-8fd9fb34cffd"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(train_X, train_y, epochs=1000, validation_split=0.15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "233/233 [==============================] - 9s 29ms/step - loss: 490545.7662 - accuracy: 0.0000e+00 - mean_squared_error: 490545.7662 - root_mean_squared_error: 697.2407 - mean_absolute_error: 534.8302 - val_loss: 401677.9688 - val_accuracy: 0.0000e+00 - val_mean_squared_error: 401677.9688 - val_root_mean_squared_error: 633.7807 - val_mean_absolute_error: 495.5408\n",
            "Epoch 2/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 440381.4993 - accuracy: 0.0000e+00 - mean_squared_error: 440381.4993 - root_mean_squared_error: 663.5150 - mean_absolute_error: 534.5905 - val_loss: 335478.8438 - val_accuracy: 0.0000e+00 - val_mean_squared_error: 335478.8438 - val_root_mean_squared_error: 579.2054 - val_mean_absolute_error: 459.6034\n",
            "Epoch 3/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 425354.5549 - accuracy: 0.0000e+00 - mean_squared_error: 425354.5549 - root_mean_squared_error: 652.0798 - mean_absolute_error: 525.0252 - val_loss: 326758.3438 - val_accuracy: 0.0000e+00 - val_mean_squared_error: 326758.3438 - val_root_mean_squared_error: 571.6278 - val_mean_absolute_error: 457.0984\n",
            "Epoch 4/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 437348.7770 - accuracy: 0.0000e+00 - mean_squared_error: 437348.7770 - root_mean_squared_error: 661.2759 - mean_absolute_error: 532.6391 - val_loss: 327678.2812 - val_accuracy: 0.0000e+00 - val_mean_squared_error: 327678.2812 - val_root_mean_squared_error: 572.4319 - val_mean_absolute_error: 456.3239\n",
            "Epoch 5/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 431054.9972 - accuracy: 0.0000e+00 - mean_squared_error: 431054.9972 - root_mean_squared_error: 656.5065 - mean_absolute_error: 526.1823 - val_loss: 390769.4688 - val_accuracy: 0.0030 - val_mean_squared_error: 390769.4688 - val_root_mean_squared_error: 625.1155 - val_mean_absolute_error: 488.7760\n",
            "Epoch 6/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 423049.6163 - accuracy: 0.0000e+00 - mean_squared_error: 423049.6163 - root_mean_squared_error: 650.3601 - mean_absolute_error: 515.9649 - val_loss: 357135.4062 - val_accuracy: 0.0030 - val_mean_squared_error: 357135.4062 - val_root_mean_squared_error: 597.6081 - val_mean_absolute_error: 469.7123\n",
            "Epoch 7/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 432404.0276 - accuracy: 0.0000e+00 - mean_squared_error: 432404.0276 - root_mean_squared_error: 657.4816 - mean_absolute_error: 526.7804 - val_loss: 348955.0625 - val_accuracy: 0.0030 - val_mean_squared_error: 348955.0625 - val_root_mean_squared_error: 590.7242 - val_mean_absolute_error: 465.6954\n",
            "Epoch 8/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 420615.9303 - accuracy: 0.0000e+00 - mean_squared_error: 420615.9303 - root_mean_squared_error: 648.4293 - mean_absolute_error: 522.3846 - val_loss: 347122.0312 - val_accuracy: 0.0030 - val_mean_squared_error: 347122.0312 - val_root_mean_squared_error: 589.1707 - val_mean_absolute_error: 465.0846\n",
            "Epoch 9/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 411114.8924 - accuracy: 0.0000e+00 - mean_squared_error: 411114.8924 - root_mean_squared_error: 640.9474 - mean_absolute_error: 515.1812 - val_loss: 371273.3438 - val_accuracy: 0.0030 - val_mean_squared_error: 371273.3438 - val_root_mean_squared_error: 609.3220 - val_mean_absolute_error: 475.1693\n",
            "Epoch 10/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 412879.3351 - accuracy: 0.0000e+00 - mean_squared_error: 412879.3351 - root_mean_squared_error: 642.4287 - mean_absolute_error: 511.3169 - val_loss: 369354.1875 - val_accuracy: 0.0030 - val_mean_squared_error: 369354.1875 - val_root_mean_squared_error: 607.7452 - val_mean_absolute_error: 473.2041\n",
            "Epoch 11/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 434488.4971 - accuracy: 0.0000e+00 - mean_squared_error: 434488.4971 - root_mean_squared_error: 659.1296 - mean_absolute_error: 530.0688 - val_loss: 391148.1875 - val_accuracy: 0.0030 - val_mean_squared_error: 391148.1875 - val_root_mean_squared_error: 625.4184 - val_mean_absolute_error: 487.2540\n",
            "Epoch 12/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 433215.5351 - accuracy: 0.0000e+00 - mean_squared_error: 433215.5351 - root_mean_squared_error: 658.1173 - mean_absolute_error: 523.6173 - val_loss: 398719.6875 - val_accuracy: 0.0030 - val_mean_squared_error: 398719.6875 - val_root_mean_squared_error: 631.4426 - val_mean_absolute_error: 488.7242\n",
            "Epoch 13/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 433308.5592 - accuracy: 0.0000e+00 - mean_squared_error: 433308.5592 - root_mean_squared_error: 658.1025 - mean_absolute_error: 524.2041 - val_loss: 359306.0000 - val_accuracy: 0.0030 - val_mean_squared_error: 359306.0000 - val_root_mean_squared_error: 599.4214 - val_mean_absolute_error: 469.0840\n",
            "Epoch 14/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 438741.8116 - accuracy: 0.0000e+00 - mean_squared_error: 438741.8116 - root_mean_squared_error: 662.2077 - mean_absolute_error: 534.0584 - val_loss: 350489.4375 - val_accuracy: 0.0030 - val_mean_squared_error: 350489.4375 - val_root_mean_squared_error: 592.0215 - val_mean_absolute_error: 466.0611\n",
            "Epoch 15/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 436891.2999 - accuracy: 0.0000e+00 - mean_squared_error: 436891.2999 - root_mean_squared_error: 660.8908 - mean_absolute_error: 528.6899 - val_loss: 371770.6250 - val_accuracy: 0.0030 - val_mean_squared_error: 371770.6250 - val_root_mean_squared_error: 609.7300 - val_mean_absolute_error: 475.5646\n",
            "Epoch 16/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 437956.6437 - accuracy: 0.0000e+00 - mean_squared_error: 437956.6437 - root_mean_squared_error: 661.5477 - mean_absolute_error: 529.1414 - val_loss: 352755.1562 - val_accuracy: 0.0030 - val_mean_squared_error: 352755.1562 - val_root_mean_squared_error: 593.9319 - val_mean_absolute_error: 467.0132\n",
            "Epoch 17/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 420816.1413 - accuracy: 0.0000e+00 - mean_squared_error: 420816.1413 - root_mean_squared_error: 648.6448 - mean_absolute_error: 519.9994 - val_loss: 359245.6250 - val_accuracy: 0.0030 - val_mean_squared_error: 359245.6250 - val_root_mean_squared_error: 599.3710 - val_mean_absolute_error: 470.0826\n",
            "Epoch 18/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 426895.2095 - accuracy: 0.0000e+00 - mean_squared_error: 426895.2095 - root_mean_squared_error: 653.3381 - mean_absolute_error: 527.4748 - val_loss: 356469.0938 - val_accuracy: 0.0030 - val_mean_squared_error: 356469.0938 - val_root_mean_squared_error: 597.0504 - val_mean_absolute_error: 469.1591\n",
            "Epoch 19/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 420394.7561 - accuracy: 0.0000e+00 - mean_squared_error: 420394.7561 - root_mean_squared_error: 648.2429 - mean_absolute_error: 519.3054 - val_loss: 351462.9062 - val_accuracy: 0.0030 - val_mean_squared_error: 351462.9062 - val_root_mean_squared_error: 592.8431 - val_mean_absolute_error: 466.4971\n",
            "Epoch 20/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 423076.0143 - accuracy: 0.0000e+00 - mean_squared_error: 423076.0143 - root_mean_squared_error: 650.4001 - mean_absolute_error: 522.2730 - val_loss: 355593.5000 - val_accuracy: 0.0030 - val_mean_squared_error: 355593.5000 - val_root_mean_squared_error: 596.3166 - val_mean_absolute_error: 468.1267\n",
            "Epoch 21/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 423370.4254 - accuracy: 0.0000e+00 - mean_squared_error: 423370.4254 - root_mean_squared_error: 650.4097 - mean_absolute_error: 521.0999 - val_loss: 355468.1875 - val_accuracy: 0.0030 - val_mean_squared_error: 355468.1875 - val_root_mean_squared_error: 596.2115 - val_mean_absolute_error: 467.8282\n",
            "Epoch 22/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 436450.5622 - accuracy: 0.0000e+00 - mean_squared_error: 436450.5622 - root_mean_squared_error: 660.5410 - mean_absolute_error: 528.0566 - val_loss: 356816.9688 - val_accuracy: 0.0030 - val_mean_squared_error: 356816.9688 - val_root_mean_squared_error: 597.3416 - val_mean_absolute_error: 468.5792\n",
            "Epoch 23/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 423521.0378 - accuracy: 0.0000e+00 - mean_squared_error: 423521.0378 - root_mean_squared_error: 650.6872 - mean_absolute_error: 520.3474 - val_loss: 344869.4062 - val_accuracy: 0.0030 - val_mean_squared_error: 344869.4062 - val_root_mean_squared_error: 587.2558 - val_mean_absolute_error: 464.2553\n",
            "Epoch 24/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 421588.4198 - accuracy: 0.0000e+00 - mean_squared_error: 421588.4198 - root_mean_squared_error: 649.1168 - mean_absolute_error: 522.2203 - val_loss: 361780.3750 - val_accuracy: 0.0030 - val_mean_squared_error: 361780.3750 - val_root_mean_squared_error: 601.4818 - val_mean_absolute_error: 471.8110\n",
            "Epoch 25/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 433443.3240 - accuracy: 0.0000e+00 - mean_squared_error: 433443.3240 - root_mean_squared_error: 658.3344 - mean_absolute_error: 524.9412 - val_loss: 355280.1562 - val_accuracy: 0.0030 - val_mean_squared_error: 355280.1562 - val_root_mean_squared_error: 596.0538 - val_mean_absolute_error: 467.6906\n",
            "Epoch 26/1000\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 432645.1040 - accuracy: 0.0000e+00 - mean_squared_error: 432645.1040 - root_mean_squared_error: 657.7280 - mean_absolute_error: 525.7720 - val_loss: 362684.9688 - val_accuracy: 0.0030 - val_mean_squared_error: 362684.9688 - val_root_mean_squared_error: 602.2333 - val_mean_absolute_error: 471.2992\n",
            "Epoch 27/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 447408.0493 - accuracy: 0.0000e+00 - mean_squared_error: 447408.0493 - root_mean_squared_error: 668.6384 - mean_absolute_error: 532.2368 - val_loss: 366503.8750 - val_accuracy: 0.0030 - val_mean_squared_error: 366503.8750 - val_root_mean_squared_error: 605.3956 - val_mean_absolute_error: 471.6750\n",
            "Epoch 28/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 418701.8156 - accuracy: 0.0000e+00 - mean_squared_error: 418701.8156 - root_mean_squared_error: 647.0343 - mean_absolute_error: 518.9421 - val_loss: 357852.8125 - val_accuracy: 0.0030 - val_mean_squared_error: 357852.8125 - val_root_mean_squared_error: 598.2080 - val_mean_absolute_error: 468.5599\n",
            "Epoch 29/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 416094.1072 - accuracy: 0.0000e+00 - mean_squared_error: 416094.1072 - root_mean_squared_error: 644.9370 - mean_absolute_error: 516.3462 - val_loss: 362840.5625 - val_accuracy: 0.0030 - val_mean_squared_error: 362840.5625 - val_root_mean_squared_error: 602.3625 - val_mean_absolute_error: 470.8757\n",
            "Epoch 30/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 435598.6656 - accuracy: 0.0000e+00 - mean_squared_error: 435598.6656 - root_mean_squared_error: 659.7034 - mean_absolute_error: 527.4554 - val_loss: 347486.2812 - val_accuracy: 0.0030 - val_mean_squared_error: 347486.2812 - val_root_mean_squared_error: 589.4797 - val_mean_absolute_error: 465.0793\n",
            "Epoch 31/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 430171.1485 - accuracy: 0.0000e+00 - mean_squared_error: 430171.1485 - root_mean_squared_error: 655.5370 - mean_absolute_error: 526.2683 - val_loss: 365448.0000 - val_accuracy: 0.0030 - val_mean_squared_error: 365448.0000 - val_root_mean_squared_error: 604.5229 - val_mean_absolute_error: 472.0563\n",
            "Epoch 32/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 431865.4374 - accuracy: 0.0000e+00 - mean_squared_error: 431865.4374 - root_mean_squared_error: 657.0099 - mean_absolute_error: 526.9553 - val_loss: 355558.9062 - val_accuracy: 0.0030 - val_mean_squared_error: 355558.9062 - val_root_mean_squared_error: 596.2876 - val_mean_absolute_error: 468.6062\n",
            "Epoch 33/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 418688.6163 - accuracy: 0.0000e+00 - mean_squared_error: 418688.6163 - root_mean_squared_error: 646.9674 - mean_absolute_error: 516.4254 - val_loss: 352442.5312 - val_accuracy: 0.0030 - val_mean_squared_error: 352442.5312 - val_root_mean_squared_error: 593.6687 - val_mean_absolute_error: 466.8766\n",
            "Epoch 34/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 421042.8456 - accuracy: 0.0000e+00 - mean_squared_error: 421042.8456 - root_mean_squared_error: 648.5208 - mean_absolute_error: 524.7109 - val_loss: 366402.4688 - val_accuracy: 0.0030 - val_mean_squared_error: 366402.4688 - val_root_mean_squared_error: 605.3119 - val_mean_absolute_error: 474.5358\n",
            "Epoch 35/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 425728.7022 - accuracy: 0.0000e+00 - mean_squared_error: 425728.7022 - root_mean_squared_error: 652.4512 - mean_absolute_error: 520.0580 - val_loss: 347206.7188 - val_accuracy: 0.0030 - val_mean_squared_error: 347206.7188 - val_root_mean_squared_error: 589.2425 - val_mean_absolute_error: 465.0563\n",
            "Epoch 36/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 425303.6205 - accuracy: 0.0000e+00 - mean_squared_error: 425303.6205 - root_mean_squared_error: 652.0952 - mean_absolute_error: 524.0848 - val_loss: 356902.4375 - val_accuracy: 0.0030 - val_mean_squared_error: 356902.4375 - val_root_mean_squared_error: 597.4131 - val_mean_absolute_error: 468.7239\n",
            "Epoch 37/1000\n",
            "233/233 [==============================] - 6s 28ms/step - loss: 446153.1346 - accuracy: 0.0000e+00 - mean_squared_error: 446153.1346 - root_mean_squared_error: 667.8423 - mean_absolute_error: 538.8643 - val_loss: 362913.8750 - val_accuracy: 0.0030 - val_mean_squared_error: 362913.8750 - val_root_mean_squared_error: 602.4233 - val_mean_absolute_error: 470.1239\n",
            "Epoch 38/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 438406.4784 - accuracy: 0.0000e+00 - mean_squared_error: 438406.4784 - root_mean_squared_error: 662.0573 - mean_absolute_error: 529.8607 - val_loss: 345661.9688 - val_accuracy: 0.0030 - val_mean_squared_error: 345661.9688 - val_root_mean_squared_error: 587.9302 - val_mean_absolute_error: 464.4669\n",
            "Epoch 39/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 451487.5140 - accuracy: 0.0000e+00 - mean_squared_error: 451487.5140 - root_mean_squared_error: 671.6975 - mean_absolute_error: 538.0281 - val_loss: 338308.6250 - val_accuracy: 0.0030 - val_mean_squared_error: 338308.6250 - val_root_mean_squared_error: 581.6431 - val_mean_absolute_error: 462.3182\n",
            "Epoch 40/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 428914.3536 - accuracy: 0.0000e+00 - mean_squared_error: 428914.3536 - root_mean_squared_error: 654.8432 - mean_absolute_error: 525.5986 - val_loss: 348950.2500 - val_accuracy: 0.0030 - val_mean_squared_error: 348950.2500 - val_root_mean_squared_error: 590.7201 - val_mean_absolute_error: 465.6223\n",
            "Epoch 41/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 432519.3236 - accuracy: 0.0000e+00 - mean_squared_error: 432519.3236 - root_mean_squared_error: 657.5161 - mean_absolute_error: 528.3166 - val_loss: 367962.0312 - val_accuracy: 0.0030 - val_mean_squared_error: 367962.0312 - val_root_mean_squared_error: 606.5988 - val_mean_absolute_error: 470.8048\n",
            "Epoch 42/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 420675.1028 - accuracy: 0.0000e+00 - mean_squared_error: 420675.1028 - root_mean_squared_error: 648.4770 - mean_absolute_error: 522.3153 - val_loss: 361022.0625 - val_accuracy: 0.0030 - val_mean_squared_error: 361022.0625 - val_root_mean_squared_error: 600.8511 - val_mean_absolute_error: 469.5119\n",
            "Epoch 43/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 436084.7493 - accuracy: 0.0000e+00 - mean_squared_error: 436084.7493 - root_mean_squared_error: 660.1418 - mean_absolute_error: 529.1748 - val_loss: 354517.5625 - val_accuracy: 0.0030 - val_mean_squared_error: 354517.5625 - val_root_mean_squared_error: 595.4138 - val_mean_absolute_error: 468.9181\n",
            "Epoch 44/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 449361.9235 - accuracy: 0.0000e+00 - mean_squared_error: 449361.9235 - root_mean_squared_error: 669.7594 - mean_absolute_error: 533.3848 - val_loss: 386938.2188 - val_accuracy: 0.0030 - val_mean_squared_error: 386938.2188 - val_root_mean_squared_error: 622.0436 - val_mean_absolute_error: 475.0842\n",
            "Epoch 45/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 420214.4038 - accuracy: 0.0000e+00 - mean_squared_error: 420214.4038 - root_mean_squared_error: 648.1478 - mean_absolute_error: 519.9284 - val_loss: 336308.6562 - val_accuracy: 0.0030 - val_mean_squared_error: 336308.6562 - val_root_mean_squared_error: 579.9213 - val_mean_absolute_error: 460.1931\n",
            "Epoch 46/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 429243.9674 - accuracy: 0.0000e+00 - mean_squared_error: 429243.9674 - root_mean_squared_error: 655.0985 - mean_absolute_error: 525.3273 - val_loss: 352420.6250 - val_accuracy: 0.0030 - val_mean_squared_error: 352420.6250 - val_root_mean_squared_error: 593.6503 - val_mean_absolute_error: 466.8146\n",
            "Epoch 47/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 410755.6234 - accuracy: 0.0000e+00 - mean_squared_error: 410755.6234 - root_mean_squared_error: 640.6410 - mean_absolute_error: 512.6656 - val_loss: 351336.6562 - val_accuracy: 0.0030 - val_mean_squared_error: 351336.6562 - val_root_mean_squared_error: 592.7366 - val_mean_absolute_error: 466.3448\n",
            "Epoch 48/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 432766.7338 - accuracy: 0.0000e+00 - mean_squared_error: 432766.7338 - root_mean_squared_error: 657.7947 - mean_absolute_error: 530.7168 - val_loss: 346228.5000 - val_accuracy: 0.0030 - val_mean_squared_error: 346228.5000 - val_root_mean_squared_error: 588.4119 - val_mean_absolute_error: 464.5989\n",
            "Epoch 49/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 434642.2277 - accuracy: 0.0000e+00 - mean_squared_error: 434642.2277 - root_mean_squared_error: 659.1000 - mean_absolute_error: 529.6334 - val_loss: 366926.1250 - val_accuracy: 0.0030 - val_mean_squared_error: 366926.1250 - val_root_mean_squared_error: 605.7443 - val_mean_absolute_error: 472.2308\n",
            "Epoch 50/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 420491.2476 - accuracy: 0.0000e+00 - mean_squared_error: 420491.2476 - root_mean_squared_error: 648.3963 - mean_absolute_error: 519.3534 - val_loss: 361100.5000 - val_accuracy: 0.0030 - val_mean_squared_error: 361100.5000 - val_root_mean_squared_error: 600.9164 - val_mean_absolute_error: 470.5170\n",
            "Epoch 51/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 426103.3953 - accuracy: 0.0000e+00 - mean_squared_error: 426103.3953 - root_mean_squared_error: 652.6917 - mean_absolute_error: 522.5706 - val_loss: 349205.3125 - val_accuracy: 0.0030 - val_mean_squared_error: 349205.3125 - val_root_mean_squared_error: 590.9360 - val_mean_absolute_error: 465.9333\n",
            "Epoch 52/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 422452.6727 - accuracy: 0.0000e+00 - mean_squared_error: 422452.6727 - root_mean_squared_error: 649.8543 - mean_absolute_error: 524.9569 - val_loss: 355810.7500 - val_accuracy: 0.0030 - val_mean_squared_error: 355810.7500 - val_root_mean_squared_error: 596.4987 - val_mean_absolute_error: 468.5053\n",
            "Epoch 53/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 444468.9064 - accuracy: 0.0000e+00 - mean_squared_error: 444468.9064 - root_mean_squared_error: 666.5243 - mean_absolute_error: 532.4282 - val_loss: 368799.5625 - val_accuracy: 0.0030 - val_mean_squared_error: 368799.5625 - val_root_mean_squared_error: 607.2887 - val_mean_absolute_error: 473.8904\n",
            "Epoch 54/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 431198.3070 - accuracy: 0.0000e+00 - mean_squared_error: 431198.3070 - root_mean_squared_error: 656.5146 - mean_absolute_error: 526.1466 - val_loss: 355405.9062 - val_accuracy: 0.0030 - val_mean_squared_error: 355405.9062 - val_root_mean_squared_error: 596.1593 - val_mean_absolute_error: 467.8735\n",
            "Epoch 55/1000\n",
            "233/233 [==============================] - 6s 28ms/step - loss: 421106.7863 - accuracy: 0.0000e+00 - mean_squared_error: 421106.7863 - root_mean_squared_error: 648.8338 - mean_absolute_error: 519.9873 - val_loss: 363699.1562 - val_accuracy: 0.0030 - val_mean_squared_error: 363699.1562 - val_root_mean_squared_error: 603.0748 - val_mean_absolute_error: 469.6351\n",
            "Epoch 56/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 421914.9087 - accuracy: 0.0000e+00 - mean_squared_error: 421914.9087 - root_mean_squared_error: 649.3406 - mean_absolute_error: 524.2449 - val_loss: 388095.1875 - val_accuracy: 0.0030 - val_mean_squared_error: 388095.1875 - val_root_mean_squared_error: 622.9728 - val_mean_absolute_error: 476.5148\n",
            "Epoch 57/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 426452.4347 - accuracy: 0.0000e+00 - mean_squared_error: 426452.4347 - root_mean_squared_error: 652.8696 - mean_absolute_error: 516.8850 - val_loss: 356565.0312 - val_accuracy: 0.0030 - val_mean_squared_error: 356565.0312 - val_root_mean_squared_error: 597.1307 - val_mean_absolute_error: 468.1188\n",
            "Epoch 58/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 419337.4173 - accuracy: 0.0000e+00 - mean_squared_error: 419337.4173 - root_mean_squared_error: 647.4874 - mean_absolute_error: 521.8853 - val_loss: 351480.0938 - val_accuracy: 0.0030 - val_mean_squared_error: 351480.0938 - val_root_mean_squared_error: 592.8575 - val_mean_absolute_error: 466.4565\n",
            "Epoch 59/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 426217.8630 - accuracy: 0.0000e+00 - mean_squared_error: 426217.8630 - root_mean_squared_error: 652.7764 - mean_absolute_error: 524.5380 - val_loss: 345576.7812 - val_accuracy: 0.0030 - val_mean_squared_error: 345576.7812 - val_root_mean_squared_error: 587.8578 - val_mean_absolute_error: 464.3922\n",
            "Epoch 60/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 436712.7126 - accuracy: 0.0000e+00 - mean_squared_error: 436712.7126 - root_mean_squared_error: 660.7202 - mean_absolute_error: 533.2244 - val_loss: 368135.6562 - val_accuracy: 0.0030 - val_mean_squared_error: 368135.6562 - val_root_mean_squared_error: 606.7418 - val_mean_absolute_error: 472.6401\n",
            "Epoch 61/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 408310.7821 - accuracy: 0.0000e+00 - mean_squared_error: 408310.7821 - root_mean_squared_error: 638.8521 - mean_absolute_error: 514.2594 - val_loss: 342185.4062 - val_accuracy: 0.0030 - val_mean_squared_error: 342185.4062 - val_root_mean_squared_error: 584.9662 - val_mean_absolute_error: 471.5969\n",
            "Epoch 62/1000\n",
            "233/233 [==============================] - 6s 28ms/step - loss: 431656.1536 - accuracy: 0.0000e+00 - mean_squared_error: 431656.1536 - root_mean_squared_error: 656.9490 - mean_absolute_error: 531.6253 - val_loss: 351885.2812 - val_accuracy: 0.0030 - val_mean_squared_error: 351885.2812 - val_root_mean_squared_error: 593.1992 - val_mean_absolute_error: 467.3592\n",
            "Epoch 63/1000\n",
            "233/233 [==============================] - 6s 28ms/step - loss: 422901.4443 - accuracy: 0.0000e+00 - mean_squared_error: 422901.4443 - root_mean_squared_error: 650.2697 - mean_absolute_error: 523.0093 - val_loss: 387139.5938 - val_accuracy: 0.0030 - val_mean_squared_error: 387139.5938 - val_root_mean_squared_error: 622.2054 - val_mean_absolute_error: 476.2108\n",
            "Epoch 64/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 419211.3687 - accuracy: 0.0000e+00 - mean_squared_error: 419211.3687 - root_mean_squared_error: 647.3699 - mean_absolute_error: 517.5861 - val_loss: 366011.1562 - val_accuracy: 0.0030 - val_mean_squared_error: 366011.1562 - val_root_mean_squared_error: 604.9886 - val_mean_absolute_error: 473.1607\n",
            "Epoch 65/1000\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 442718.5577 - accuracy: 0.0000e+00 - mean_squared_error: 442718.5577 - root_mean_squared_error: 665.1579 - mean_absolute_error: 529.0569 - val_loss: 351443.8438 - val_accuracy: 0.0030 - val_mean_squared_error: 351443.8438 - val_root_mean_squared_error: 592.8270 - val_mean_absolute_error: 466.4650\n",
            "Epoch 66/1000\n",
            " 93/233 [==========>...................] - ETA: 3s - loss: 410997.5704 - accuracy: 0.0000e+00 - mean_squared_error: 410997.5704 - root_mean_squared_error: 640.3117 - mean_absolute_error: 512.0511"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TpnwIhCSUeu"
      },
      "source": [
        "root_mean_squared_error = history.history['val_root_mean_squared_error']\n",
        "best_epoch = root_mean_squared_error.index(min(root_mean_squared_error)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Vir9zS-sYm"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(train_X, train_y, epochs=best_epoch, validation_split=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlpeid6K-0UT"
      },
      "source": [
        "# eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "# print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8AD4j1dKhys"
      },
      "source": [
        "# # design network\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(224, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# model.add(BatchNormalization(axis=-1, \n",
        "#                             momentum=0.99,\n",
        "#                             epsilon=0.001,\n",
        "#                             center=True,\n",
        "#                             scale=True,\n",
        "#                             beta_initializer='zeros',\n",
        "#                             gamma_initializer='ones',\n",
        "#                             moving_mean_initializer='zeros',\n",
        "#                             moving_variance_initializer='ones',\n",
        "#                             beta_regularizer=None,\n",
        "#                             gamma_regularizer=None,\n",
        "#                             beta_constraint=None,\n",
        "#                             gamma_constraint=None\n",
        "#                             ))\n",
        "# #model.add(Dropout(rate=0.25))\n",
        "# model.add(Dense(1))\n",
        "\n",
        "\n",
        "# model.compile(loss='mae',\n",
        "#               optimizer=SGD(lr=1e-05),\n",
        "#               metrics=[\"accuracy\", \n",
        "#                        MeanSquaredError(), \n",
        "#                        RootMeanSquaredError(),\n",
        "#                        MeanAbsoluteError()])\n",
        "\n",
        "# # fit network\n",
        "# history = model.fit(train_X, \n",
        "#                     train_y,\n",
        "#                     validation_split=0.15,\n",
        "#                     epochs=166,\n",
        "#                     batch_size=60,\n",
        "#                     verbose=2,\n",
        "#                     shuffle=False)\n",
        "\n",
        "# # plot history\n",
        "# pyplot.plot(history.history['loss'], label='train')\n",
        "# pyplot.plot(history.history['val_loss'], label='test')\n",
        "# pyplot.legend()\n",
        "# pyplot.show()\n",
        "\n",
        "# # make a prediction\n",
        "# yhat = model.predict(test_X)\n",
        "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "\n",
        "# # invert scaling for forecast\n",
        "# oi = np.random.randint(1,101,size=(853,12))\n",
        "# inv_yhat = concatenate((yhat, oi), axis=1)\n",
        "# print(inv_yhat.shape)\n",
        "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "# inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "# # invert scaling for actual\n",
        "# test_y = test_y.reshape((len(test_y), 1))\n",
        "# inv_y = concatenate((test_y, oi), axis=1)\n",
        "# inv_y = scaler.inverse_transform(inv_y)\n",
        "# inv_y = inv_y[:,0]\n",
        "\n",
        "# # calculate R2\n",
        "# r2 = r2_score(inv_y, inv_yhat)\n",
        "# adj_r2 = adj_r2(r2)\n",
        "# print('Test R2: %.3f' % r2)\n",
        "# print('Test ADJ R2: %.3f' % adj_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIzPfTiaZ4yu"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['root_mean_squared_error'])\n",
        "plt.plot(history.history['val_root_mean_squared_error'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}