{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Deep Learning2",
      "language": "python",
      "name": "deep_learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSTM_Adam 4layers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V80ejwHT5_vv"
      },
      "source": [
        "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TJDq3Tv5_v7"
      },
      "source": [
        "# prepare data for lstm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJ8N4xB5_v9"
      },
      "source": [
        "# https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df =  DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(-i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLHE-1Ts5_v-"
      },
      "source": [
        "# load dataset\n",
        "dataset = read_csv('SeoulBikeData_168.csv', encoding= 'unicode_escape', header=0, index_col=0)\n",
        "\n",
        "values = dataset.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xztLdIb5_v-"
      },
      "source": [
        "# encode the categorical variables into integers\n",
        "label_encoder = LabelEncoder()\n",
        "values[:,12] = label_encoder.fit_transform(values[:,12])\n",
        "values[:,10] = label_encoder.fit_transform(values[:,10])\n",
        "values[:,11] = label_encoder.fit_transform(values[:,11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnaVTr5S5_v_"
      },
      "source": [
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#scaled = scaler.fit_transform(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM32xHas5_wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50da8ec-d28f-4e06-a457-c7e9f6a0e4b0"
      },
      "source": [
        "# frame as supervised learning\n",
        "hours_to_consider = 168\n",
        "reframed = series_to_supervised(values, hours_to_consider, 1)\n",
        "\n",
        "# drop columns we don't want to predict\n",
        "columns_to_keep = list()\n",
        "for i in range(337,reframed.shape[1]+1,14):\n",
        "  columns_to_keep.append(i)\n",
        "\n",
        "n_cols = [i for i in range (337,reframed.shape[1]+1)]\n",
        "for i in columns_to_keep:\n",
        "    n_cols.remove(i)\n",
        "n_cols2 = [x - 1 for x in n_cols]\n",
        "print(reframed)\n",
        "reframed = reframed.drop(reframed.columns[[n_cols2]], axis=1, inplace=False)\n",
        "print(reframed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      var1(t-168)  var2(t-168)  var3(t-168)  ...  var12(t)  var13(t)  var14(t)\n",
            "0           254.0          0.0         -5.2  ...       1.0       1.0      12.0\n",
            "1           204.0          1.0         -5.5  ...       1.0       1.0      12.0\n",
            "2           173.0          2.0         -6.0  ...       1.0       1.0      12.0\n",
            "3           107.0          3.0         -6.2  ...       1.0       1.0      12.0\n",
            "4            78.0          4.0         -6.0  ...       1.0       1.0      12.0\n",
            "...           ...          ...          ...  ...       ...       ...       ...\n",
            "8755       1003.0         19.0          4.2  ...       1.0       1.0      11.0\n",
            "8756        764.0         20.0          3.4  ...       1.0       1.0      11.0\n",
            "8757        694.0         21.0          2.6  ...       1.0       1.0      11.0\n",
            "8758        712.0         22.0          2.1  ...       1.0       1.0      11.0\n",
            "8759        584.0         23.0          1.9  ...       1.0       1.0      11.0\n",
            "\n",
            "[8760 rows x 2366 columns]\n",
            "      var1(t-168)  var2(t-168)  var3(t-168)  ...  var1(t-2)  var1(t-1)  var1(t)\n",
            "0           254.0          0.0         -5.2  ...      167.0      253.0    249.0\n",
            "1           204.0          1.0         -5.5  ...      136.0      167.0    253.0\n",
            "2           173.0          2.0         -6.0  ...       75.0      136.0    167.0\n",
            "3           107.0          3.0         -6.2  ...       47.0       75.0    136.0\n",
            "4            78.0          4.0         -6.0  ...       39.0       47.0     75.0\n",
            "...           ...          ...          ...  ...        ...        ...      ...\n",
            "8755       1003.0         19.0          4.2  ...      679.0      767.0   1007.0\n",
            "8756        764.0         20.0          3.4  ...      729.0      679.0    767.0\n",
            "8757        694.0         21.0          2.6  ...      548.0      729.0    679.0\n",
            "8758        712.0         22.0          2.1  ...      499.0      548.0    729.0\n",
            "8759        584.0         23.0          1.9  ...      507.0      499.0    548.0\n",
            "\n",
            "[8760 rows x 481 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URZ1t7D7K9h7"
      },
      "source": [
        "import pandas as pd\n",
        "my_list = pd.DataFrame(reframed)\n",
        "my_list = my_list.columns.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUQgR2Ue5_wB"
      },
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "train_ratio = 0.85\n",
        "n_train_hours = int(365 * hours_to_consider * train_ratio)\n",
        "\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, 1:], train[:, 0]\n",
        "test_X, test_y = test[:, 1:], test[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r82ZRX7w_vzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1af7318-b810-4099-dbfa-fbe04af06104"
      },
      "source": [
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8760, 1, 480) (8760,) (0, 1, 480) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcWBXXCA5_wC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b26dfa5-6bcd-4ef0-c823-202530955944"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "from keras.metrics import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.metrics import MeanAbsoluteError\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "!pip install keras-tuner\n",
        "from kerastuner.tuners import RandomSearch, Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers import Reshape\n",
        "\n",
        "def adj_r2(r2):\n",
        "  n = train_X.shape[0]\n",
        "  p = train_X.shape[2]\n",
        "  return (1-(1-r2)*(n-1)/(n-p-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=9a1c7893206f2588cc6f90b044e19f7cd0267388e1990ef6d0949ed763ff2773\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=082986fa2eedc05d608b0a69301c5f7d9cb75b4077369194d2481b420343babc\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JHbtIkP3jQa",
        "outputId": "b4f707eb-ded6-49ee-ef07-069a589ed01c"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "  model.add(LSTM(hp_units,\n",
        "                 input_shape=(train_X.shape[1], train_X.shape[2]),\n",
        "                 return_sequences=True\n",
        "                 ))\n",
        "  model.add(BatchNormalization(axis=-1, \n",
        "                            momentum=0.99,\n",
        "                            epsilon=0.001,\n",
        "                            center=True,\n",
        "                            scale=True,\n",
        "                            beta_initializer='zeros',\n",
        "                            gamma_initializer='ones',\n",
        "                            moving_mean_initializer='zeros',\n",
        "                            moving_variance_initializer='ones',\n",
        "                            beta_regularizer=None,\n",
        "                            gamma_regularizer=None,\n",
        "                            beta_constraint=None,\n",
        "                            gamma_constraint=None\n",
        "                            ))\n",
        "\n",
        "  hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "  model.add(LSTM(hp_units2, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
        "  model.add(BatchNormalization(axis=-1, \n",
        "                            momentum=0.99,\n",
        "                            epsilon=0.001,\n",
        "                            center=True,\n",
        "                            scale=True,\n",
        "                            beta_initializer='zeros',\n",
        "                            gamma_initializer='ones',\n",
        "                            moving_mean_initializer='zeros',\n",
        "                            moving_variance_initializer='ones',\n",
        "                            beta_regularizer=None,\n",
        "                            gamma_regularizer=None,\n",
        "                            beta_constraint=None,\n",
        "                            gamma_constraint=None))\n",
        "  \n",
        "  hp_units3 = hp.Int('units3', min_value=32, max_value=512, step=32)\n",
        "  model.add(LSTM(hp_units3, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
        "  model.add(BatchNormalization(axis=-1, \n",
        "                            momentum=0.99,\n",
        "                            epsilon=0.001,\n",
        "                            center=True,\n",
        "                            scale=True,\n",
        "                            beta_initializer='zeros',\n",
        "                            gamma_initializer='ones',\n",
        "                            moving_mean_initializer='zeros',\n",
        "                            moving_variance_initializer='ones',\n",
        "                            beta_regularizer=None,\n",
        "                            gamma_regularizer=None,\n",
        "                            beta_constraint=None,\n",
        "                            gamma_constraint=None))\n",
        "  \n",
        "  hp_units4 = hp.Int('units4', min_value=32, max_value=512, step=32)\n",
        "  model.add(LSTM(hp_units4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  model.add(BatchNormalization(axis=-1, \n",
        "                            momentum=0.99,\n",
        "                            epsilon=0.001,\n",
        "                            center=True,\n",
        "                            scale=True,\n",
        "                            beta_initializer='zeros',\n",
        "                            gamma_initializer='ones',\n",
        "                            moving_mean_initializer='zeros',\n",
        "                            moving_variance_initializer='ones',\n",
        "                            beta_regularizer=None,\n",
        "                            gamma_regularizer=None,\n",
        "                            beta_constraint=None,\n",
        "                            gamma_constraint=None))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('lr', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6])\n",
        "  \n",
        "  model.compile(optimizer=Adam(hp_learning_rate),\n",
        "                loss=\"mse\",\n",
        "                metrics=['accuracy', MeanSquaredError(), RootMeanSquaredError(),MeanAbsoluteError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "tuner = Hyperband(model_builder,\n",
        "                  objective='mean_squared_error',\n",
        "                  max_epochs=100,\n",
        "                  factor=10,\n",
        "                  directory='my_dir',\n",
        "                  hyperband_iterations=5,\n",
        "                  project_name='logss')\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "tuner.search(train_X, train_y, epochs=1000, validation_split=0.15, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Layer 1: {best_hps.get('units1')}\n",
        "Layer 2: {best_hps.get('units2')}\n",
        "Layer 3: {best_hps.get('units3')}\n",
        "Layer 4: {best_hps.get('units4')}\n",
        "\n",
        "Learning rate: {best_hps.get('lr')}.\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 616 Complete [00h 00m 26s]\n",
            "mean_squared_error: 452396.9375\n",
            "\n",
            "Best mean_squared_error So Far: 91128.9609375\n",
            "Total elapsed time: 11h 57m 54s\n",
            "\n",
            "Search: Running Trial #617\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "units1            |480               |160               \n",
            "units2            |128               |416               \n",
            "units3            |192               |384               \n",
            "units4            |64                |256               \n",
            "lr                |0.001             |0.0001            \n",
            "tuner/epochs      |1                 |100               \n",
            "tuner/initial_e...|0                 |0                 \n",
            "tuner/bracket     |2                 |0                 \n",
            "tuner/round       |0                 |0                 \n",
            "\n",
            " 58/233 [======>.......................] - ETA: 5s - loss: 919740.8739 - accuracy: 0.0092 - mean_squared_error: 919740.8739 - root_mean_squared_error: 958.9375 - mean_absolute_error: 691.2193"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOTX2CXz-d6i"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(train_X, train_y, epochs=1000, validation_split=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TpnwIhCSUeu"
      },
      "source": [
        "root_mean_squared_error = history.history['val_root_mean_squared_error']\n",
        "best_epoch = root_mean_squared_error.index(min(root_mean_squared_error)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Vir9zS-sYm"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(train_X, train_y, epochs=best_epoch, validation_split=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlpeid6K-0UT"
      },
      "source": [
        "# eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "# print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8AD4j1dKhys"
      },
      "source": [
        "# # design network\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(224, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# model.add(BatchNormalization(axis=-1, \n",
        "#                             momentum=0.99,\n",
        "#                             epsilon=0.001,\n",
        "#                             center=True,\n",
        "#                             scale=True,\n",
        "#                             beta_initializer='zeros',\n",
        "#                             gamma_initializer='ones',\n",
        "#                             moving_mean_initializer='zeros',\n",
        "#                             moving_variance_initializer='ones',\n",
        "#                             beta_regularizer=None,\n",
        "#                             gamma_regularizer=None,\n",
        "#                             beta_constraint=None,\n",
        "#                             gamma_constraint=None\n",
        "#                             ))\n",
        "# #model.add(Dropout(rate=0.25))\n",
        "# model.add(Dense(1))\n",
        "\n",
        "\n",
        "# model.compile(loss='mae',\n",
        "#               optimizer=SGD(lr=1e-05),\n",
        "#               metrics=[\"accuracy\", \n",
        "#                        MeanSquaredError(), \n",
        "#                        RootMeanSquaredError(),\n",
        "#                        MeanAbsoluteError()])\n",
        "\n",
        "# # fit network\n",
        "# history = model.fit(train_X, \n",
        "#                     train_y,\n",
        "#                     validation_split=0.15,\n",
        "#                     epochs=166,\n",
        "#                     batch_size=60,\n",
        "#                     verbose=2,\n",
        "#                     shuffle=False)\n",
        "\n",
        "# # plot history\n",
        "# pyplot.plot(history.history['loss'], label='train')\n",
        "# pyplot.plot(history.history['val_loss'], label='test')\n",
        "# pyplot.legend()\n",
        "# pyplot.show()\n",
        "\n",
        "# # make a prediction\n",
        "# yhat = model.predict(test_X)\n",
        "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "\n",
        "# # invert scaling for forecast\n",
        "# oi = np.random.randint(1,101,size=(853,12))\n",
        "# inv_yhat = concatenate((yhat, oi), axis=1)\n",
        "# print(inv_yhat.shape)\n",
        "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "# inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "# # invert scaling for actual\n",
        "# test_y = test_y.reshape((len(test_y), 1))\n",
        "# inv_y = concatenate((test_y, oi), axis=1)\n",
        "# inv_y = scaler.inverse_transform(inv_y)\n",
        "# inv_y = inv_y[:,0]\n",
        "\n",
        "# # calculate R2\n",
        "# r2 = r2_score(inv_y, inv_yhat)\n",
        "# adj_r2 = adj_r2(r2)\n",
        "# print('Test R2: %.3f' % r2)\n",
        "# print('Test ADJ R2: %.3f' % adj_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIzPfTiaZ4yu"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['root_mean_squared_error'])\n",
        "plt.plot(history.history['val_root_mean_squared_error'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}